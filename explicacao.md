## Justificativa da Arquitetura de Data Lake para E-Shop (Vers√£o Atualizada)

Com base nos requisitos do trabalho e nas melhores pr√°ticas de arquitetura de dados, sua arquitetura foi estruturada em camadas bem definidas que atendem aos objetivos de integra√ß√£o, processamento e an√°lise de dados da empresa E-Shop. A atualiza√ß√£o reflete uma abordagem mais flex√≠vel e realista onde a camada Silver pode ser acessada diretamente por consultas anal√≠ticas e modelos de machine learning.[1]

### üîµ Data Sources (Fontes de Dados)

**Componentes:** Sistemas Transacionais OLTP, APIs e Web Services, Streaming em Tempo Real, Arquivos e Logs, Dados N√£o Estruturados

**Justificativa:** A diversidade de fontes de dados reflete a realidade da E-Shop, que coleta dados de transa√ß√µes, perfis de clientes, produtos, hist√≥rico de navega√ß√£o e avalia√ß√µes. Esta arquitetura multifontes permite:[1]

- **Sistemas Transacionais OLTP:** Captura de dados de compras, valores e formas de pagamento[1]
- **APIs e Web Services:** Integra√ß√£o com sistemas externos e coleta de dados de clientes[1]
- **Streaming em Tempo Real:** Monitoramento de comportamento de navega√ß√£o e eventos em tempo real[2][3]
- **Arquivos e Logs:** Armazenamento de logs de navega√ß√£o e dados de cliques[1]
- **Dados N√£o Estruturados:** Coment√°rios de produtos, avalia√ß√µes e imagens[1]

Esta abordagem heterog√™nea √© fundamental para um data lake, que por defini√ß√£o deve aceitar todos os tipos de dados sem pr√©-processamento.[4][5]

### üü¢ Camada de Ingest√£o

**Componentes:** Ingest√£o em Batch (I1) e Ingest√£o em Streaming (I2)

**Justificativa da Separa√ß√£o:**

**Ingest√£o em Batch (I1):** Configurada para processar dados de sistemas transacionais, APIs, arquivos e logs em lotes programados. Esta abordagem √© ideal quando:[3][6]
- Os dados n√£o precisam ser consumidos em tempo real[3]
- H√° grandes volumes acumulados que podem ser processados em hor√°rios espec√≠ficos (ex: diariamente √† noite)[3]
- √â necess√°rio minimizar o impacto no ambiente de produ√ß√£o[3]
- Integra√ß√£o com sistemas legados que n√£o suportam streaming[6]

**Ingest√£o em Streaming (I2):** Dedicada a processar dados em tempo real. Esta camada √© essencial para:[7][3]
- Capturar eventos de navega√ß√£o e cliques instantaneamente[7]
- Alimentar sistemas de recomenda√ß√£o com dados frescos[5][8]
- Gerar notifica√ß√µes e an√°lises em tempo real[7]
- Detectar fraudes e anomalias em transa√ß√µes[7]

Esta **arquitetura dual batch-streaming** √© conhecida como Arquitetura Lambda, que combina processamento de alta lat√™ncia (batch) com baixa lat√™ncia (streaming), permitindo an√°lises hist√≥ricas profundas e insights em tempo real simultaneamente.[6][3][7]

### üü° Camada de Armazenamento - Arquitetura Medalh√£o

**Estrutura:** Bronze ‚Üí Silver ‚Üí Gold

**Justificativa da Escolha:**

A Arquitetura Medalh√£o foi selecionada por ser um padr√£o de design reconhecido pela Databricks que organiza logicamente os dados em um lakehouse, melhorando incremental e progressivamente a qualidade dos dados.[9][10][11][2]

#### **Zona Bronze (Raw - Dados Brutos)**
**Caracter√≠sticas:** Dados Brutos, Formato Original, Auditoria Completa[2]

**Justificativa:**
- **Preserva√ß√£o da integridade:** Armazena dados exatamente como chegam das fontes, sem transforma√ß√£o[9][2]
- **Auditoria e rastreabilidade:** Permite reconstruir todo o pipeline de dados caso necess√°rio[11][2]
- **Linhagem de dados:** Facilita o cumprimento de regulamenta√ß√µes como LGPD[12][9]
- **Reprodutibilidade:** Se uma regra de neg√≥cio mudar, √© poss√≠vel reprocessar tudo a partir da origem[11]
- **Schema-on-read:** Permite armazenar dados sem esquema definido previamente[13][4]
- **Recupera√ß√£o de erros:** Possibilita corrigir problemas em etapas anteriores do pipeline[2]

Para a E-Shop, esta camada armazena transa√ß√µes brutas, logs de navega√ß√£o originais, avalia√ß√µes de produtos e dados de clientes sem tratamento.[1]

**Exemplo pr√°tico:** Se um algoritmo de limpeza na camada Silver introduzir um bug e remover dados leg√≠timos, a Bronze preserva os dados originais para reprocessamento.[11]

#### **Zona Silver (Refined - Dados Refinados)**
**Caracter√≠sticas:** Dados Limpos, Validados, Padronizados[2]

**Justificativa:**
- **Qualidade de dados:** Aplica√ß√£o de limpeza, valida√ß√£o e remo√ß√£o de duplicatas[14][2]
- **Padroniza√ß√£o:** Normaliza√ß√£o de formatos e estabelecimento de relacionamentos[10][2]
- **Modelo corporativo:** Estrutura√ß√£o baseada em dom√≠nios de neg√≥cio (Cliente, Produto, Transa√ß√£o)[15]
- **Conformidade:** Implementa√ß√£o de regras de qualidade e valida√ß√£o[16][14]
- **Acesso intermedi√°rio:** Ponto √≥timo para cientistas de dados explorarem dados semi-processados[11][2]

Para a E-Shop, esta camada consolida perfis de clientes √∫nicos, produtos validados e transa√ß√µes consistentes, prontos para an√°lise.[1]

**Import√¢ncia:** A Silver √© o ponto de partida ideal para Data Science, pois os dados j√° est√£o limpos mas ainda mant√™m detalhes granulares que podem ser √∫teis para explora√ß√£o e modelagem.[5][2][11]

#### **Zona Gold (Curated - Dados Curados)**
**Caracter√≠sticas:** Dados Agregados, Modelados, Prontos para Neg√≥cio[2]

**Justificativa:**
- **Otimiza√ß√£o para consumo:** Dados desnormalizados e agregados para consultas r√°pidas[9][2]
- **KPIs pr√©-calculados:** M√©tricas de vendas, produtos mais vendidos, taxa de convers√£o[10][2]
- **Modelagem dimensional:** Star schema ou esquemas otimizados para BI[15][9]
- **Terminologia de neg√≥cio:** Dados apresentados na linguagem dos usu√°rios finais[11][2]
- **Performance garantida:** Consultas r√°pidas para dashboards cr√≠ticos[9][2]

Para a E-Shop, esta camada cont√©m an√°lises de vendas consolidadas, segmenta√ß√£o de clientes e dados prontos para dashboards.[1]

**Benef√≠cios da Arquitetura Medalh√£o:**[9][2][11]
- Separa√ß√£o de responsabilidades entre equipes (Engenheiros nas camadas Bronze/Silver, Analistas na Gold)[11]
- Simplicidade e intuitividade para comunica√ß√£o entre √°reas t√©cnicas e de neg√≥cio[11]
- Qualidade crescente e rastreabilidade em cada etapa[10][2]
- Flexibilidade de acesso em m√∫ltiplos n√≠veis de refinamento[2]

### üü£ Camada de Processamento

**Componentes:** Motor de Processamento Distribu√≠do (P1), Transforma√ß√µes e Limpeza (P2), Enriquecimento de Dados (P3), Jobs ETL/ELT (P4)

**Justificativa:**

**Motor de Processamento Distribu√≠do (Apache Spark/Hadoop - P1):**[17][18][19]
- **Escalabilidade:** Processa grandes volumes de dados distribuindo a carga entre m√∫ltiplos n√≥s[18][17]
- **Performance:** Spark utiliza processamento em mem√≥ria (RAM), exponencialmente mais r√°pido que acesso a disco[19][18]
- **Versatilidade:** Suporta m√∫ltiplos tipos de processamento: batch, streaming, SQL, machine learning[17][19]
- **Compatibilidade:** Funciona com diversos formatos (Parquet, JSON, CSV, Avro)[17]

Para a E-Shop, o Spark √© ideal para processar grandes volumes de transa√ß√µes (milh√µes/dia) e preparar dados para recomenda√ß√µes de produtos.[5][1]

**Transforma√ß√µes e Limpeza (P2):**[14][16]
- **Valida√ß√£o automatizada:** Aplica√ß√£o de regras de qualidade durante o processamento[16][14]
- **Padroniza√ß√£o:** Normaliza√ß√£o de dados para an√°lises consistentes[14]
- **Remo√ß√£o de duplicatas:** Garantia de unicidade de registros[2]
- **Tratamento de nulos:** Estrat√©gias para lidar com valores faltantes[16][14]
- **Outliers:** Detec√ß√£o e tratamento de anomalias[16]

Alimenta a zona **Silver**.[2]

**Enriquecimento de Dados (P3):**[20][12]
- **Integra√ß√£o de m√∫ltiplas fontes:** Combina dados de transa√ß√µes com perfis de clientes[1]
- **Adi√ß√£o de contexto:** Enriquece dados com informa√ß√µes externas (ex: dados demogr√°ficos, tend√™ncias de mercado)[12]
- **Agrega√ß√µes:** Calcula m√©tricas derivadas para an√°lises[2]
- **Jointures:** Relaciona dados de diferentes dom√≠nios[12]

Alimenta a zona **Gold**.[2]

**Jobs ETL/ELT (P4):**[9]
- **Abordagem ELT preferencial:** Extrai, carrega e depois transforma, aproveitando o poder do data lake[9]
- **Orquestra√ß√£o:** Coordena execu√ß√£o de m√∫ltiplos jobs em sequ√™ncia[10][2]
- **Transforma√ß√µes progressivas:** Move dados de Bronze ‚Üí Silver ‚Üí Gold aplicando regras incrementais[10][2]
- **Agendamento:** Executa jobs em hor√°rios otimizados[6]
- **Monitoramento:** Rastreia sucesso/falha de cada transforma√ß√£o[12]

**Fluxo de Processamento:**
1. BRONZE recebe dados via event-driven (IB ‚Üí Event ‚Üí BRONZE)[2]
2. BRONZE ‚Üí P4 (inicia processamento de jobs ETL)[2]
3. P4 ‚Üí P2 (aplica transforma√ß√µes e limpeza)[14][16]
4. P2 ‚Üí SILVER (armazena dados limpos)[2]
5. SILVER ‚Üí P1 (carrega em motor distribu√≠do)[18]
6. P1 ‚Üí P3 (aplica enriquecimento)[20][12]
7. P3 ‚Üí GOLD (armazena dados finais agregados)[2]

### üî¥ Camada de Governan√ßa e Seguran√ßa

**Componentes:** Cat√°logo de Metadados (GOV1), Linhagem de Dados (GOV2), Controle de Acesso (GOV3), Criptografia e Compliance (GOV4), Qualidade de Dados (GOV5)

**Justificativa:**

**Cat√°logo de Metadados (GOV1):**[12][14]
- **Descoberta de dados:** Facilita localizar e entender os dados dispon√≠veis[12]
- **Documenta√ß√£o centralizada:** Registra origem, transforma√ß√µes e destino dos dados[20]
- **Organiza√ß√£o:** Indexa e categoriza dados para busca eficiente[4][12]
- **Gloss√°rio corporativo:** Define terminologia padronizada[14][12]

Conecta a **STORAGE** (onde os dados residem) e **CONSUMPTION** (onde s√£o acessados).[14][12]

**Linhagem de Dados (GOV2):**[21][22][12]
- **Rastreabilidade end-to-end:** Documenta o fluxo completo dos dados desde a origem[20][12]
- **Compliance regulat√≥rio:** Essencial para atender LGPD e GDPR[21][12]
- **An√°lise de impacto:** Identifica quais relat√≥rios s√£o afetados por mudan√ßas nos dados[22][20]
- **Auditoria:** Permite identificar quando e por quem os dados foram modificados[12]

Conecta a **STORAGE** para rastrear transforma√ß√µes em cada zona da Medalh√£o.[22][20][12]

**Controle de Acesso (GOV3):**[23][14]
- **Seguran√ßa granular:** Define quem pode acessar quais dados[14]
- **Prote√ß√£o de dados sens√≠veis:** Essencial para dados de clientes e transa√ß√µes[14]
- **Conformidade:** Atende requisitos de privacidade da LGPD[24][14]
- **Auditoria de acesso:** Registra quem acessou quais dados e quando[14]

Conecta ao **C1 (Ferramentas de BI)** para garantir que apenas usu√°rios autorizados visualizem dados sens√≠veis.[23][14]

**Criptografia e Compliance (GOV4):**[25][26][24]
- **Prote√ß√£o em repouso e tr√¢nsito:** Criptografia de dados em todo o ambiente[27][25]
- **LGPD:** Requisito obrigat√≥rio para prote√ß√£o de dados pessoais[24][25]
- **Confidencialidade:** Garante que dados s√≥ sejam acessados por pessoas autorizadas[25]
- **Integridade:** Valida que dados n√£o foram violados[25]
- **N√£o-rep√∫dio:** Rastreia quem realizou cada a√ß√£o[25]

Conecta a **STORAGE** para proteger dados armazenados em todas as zonas.[26][24][25]

**Qualidade de Dados (GOV5):**[28][16][14]
- **Valida√ß√£o cont√≠nua:** Monitoramento de completude, precis√£o e consist√™ncia[16][14]
- **Detec√ß√£o de anomalias:** Identifica√ß√£o de erros e inconsist√™ncias[28][14]
- **M√©tricas de qualidade:** Rastreamento de porcentagem de valores nulos, distribui√ß√£o de dados[28]
- **Automa√ß√£o:** Processos automatizados de verifica√ß√£o e corre√ß√£o[16][14]
- **Alertas:** Notifica quando qualidade cai abaixo de limites aceit√°veis[16]

Conecta ao **PROCESSING** para implementar valida√ß√µes durante transforma√ß√µes.[28][16][14]

**Import√¢ncia da Governan√ßa:** Em um data lake sem governan√ßa robusta, h√° risco de "data swamp" (p√¢ntano de dados) onde ningu√©m entende a qualidade ou origem dos dados.[23][24][14]

### üü† Camada de Consumo e Exposi√ß√£o

**Componentes:** Ferramentas de BI e Visualiza√ß√£o (C1), Data Science e ML (C2), APIs de Dados (C3), Aplica√ß√µes Anal√≠ticas (C4), Consultas Ad-hoc (C5)

**Justificativa:**

**Ferramentas de BI e Visualiza√ß√£o (C1):**[29][30]
- **Power BI, Tableau, Qlik Sense:** Ferramentas l√≠deres para cria√ß√£o de dashboards e relat√≥rios[29]
- **An√°lise visual:** Permite monitoramento de vendas e prefer√™ncias de clientes[29][1]
- **Self-service:** Democratiza acesso aos dados para usu√°rios de neg√≥cio[4]
- **KPIs em tempo real:** Monitoramento de m√©tricas cr√≠ticas[29]

Consome dados da **GOLD** (dados pr√©-agregados e otimizados).[29][1]

**Data Science e Machine Learning (C2):**[8][31][5]
- **An√°lise preditiva:** Treinamento de modelos de recomenda√ß√£o baseados em hist√≥rico[5][1]
- **Segmenta√ß√£o de clientes:** Identifica√ß√£o de padr√µes de comportamento[32][8]
- **Otimiza√ß√£o de marketing:** Personaliza√ß√£o de experi√™ncias de compra[8][32]
- **Detec√ß√£o de anomalias:** Fraudes e comportamentos incomuns[8]

**Acesso direto √† SILVER:** A nova conex√£o `SILVER -.-> C2` permite que cientistas de dados acessem dados granulares sem passar pela agrega√ß√£o da Gold. Isto √© cr√≠tico para:[5][11][2]
- **Explora√ß√£o:** Investigar padr√µes em dados detalhados[5]
- **Feature engineering:** Criar vari√°veis derivadas para modelos[5]
- **Modelagem iterativa:** Testar diferentes abordagens rapidamente[5]

Para a E-Shop, esta camada √© cr√≠tica para o sistema de recomenda√ß√£o de produtos solicitado.[8][5][1]

**APIs de Dados (C3):**[33][34][35]
- **Exposi√ß√£o controlada:** Permite que aplica√ß√µes consumam dados via REST APIs[35][33]
- **Integra√ß√£o com sistemas:** Facilita uso dos dados por outras plataformas[36][37]
- **Acesso program√°tico:** Suporta automa√ß√µes e integra√ß√µes[34][33]
- **Escalabilidade:** Suporta alto volume de requisi√ß√µes[33]

Consome dados da **GOLD** atrav√©s de endpoints otimizados.[34][35][33]

**Aplica√ß√µes Anal√≠ticas (C4):**[38][5]
- **Aplica√ß√µes personalizadas:** Sistemas espec√≠ficos alimentados pelo data lake[5]
- **Tempo real:** Dashboards e alertas em tempo real[5]
- **Mobile e web:** Aplica√ß√µes para m√∫ltiplas plataformas[5]

Integra-se com **C1, C2, C3** para consumir dados.[38][5]

**Consultas Ad-hoc (C5):**[4][5]
- **Explora√ß√£o livre:** Permite analistas explorarem dados sem restri√ß√µes[4][5]
- **Flexibilidade:** SQL e outras linguagens para an√°lise explorat√≥ria[4]
- **Descoberta:** Busca por padr√µes n√£o-planejados[5]

**Acesso direto √† SILVER:** A nova conex√£o `SILVER -.-> C5` permite que analistas executem consultas SQL diretamente em dados refinados sem agrega√ß√£o. Justificativa:[4][5][2]
- **Performance intermedi√°ria:** Silver √© mais r√°pido que Bronze (dados limpos) mas mant√©m granularidade de dados[11][2]
- **An√°lises explorat√≥rias:** Perfeito para perguntas ad-hoc que n√£o justificam pr√©-agrega√ß√£o na Gold[11][5]
- **Custo-benef√≠cio:** Evita manuten√ß√£o de Gold para cada poss√≠vel consulta[11][2]

### Decis√µes Arquiteturais Adicionais

#### **Arquitetura Event-Driven**

O n√≥ "Event" entre a ingest√£o batch e a zona Bronze representa uma arquitetura orientada a eventos, permitindo:[3][7]
- **Desacoplamento:** Separa√ß√£o entre produtores e consumidores de dados[3]
- **Escalabilidade:** Processamento ass√≠ncrono e distribu√≠do[7]
- **Rastreabilidade:** Cada evento √© registrado para auditoria[12]
- **Flexibilidade:** M√∫ltiplos consumidores (processadores) podem processar o mesmo evento[7]

#### **Conex√£o Tracejada IS -.-> BRONZE**

A ingest√£o em streaming usa conex√£o tracejada porque:[6][7]
- **Continuidade:** Ingere dados continuamente (n√£o em lotes discretos)[7]
- **Ass√≠ncrona:** N√£o aguarda lote completo para processar[7]
- **Baixa lat√™ncia:** Ideal para eventos que precisam de resposta imediata[7]

#### **Formato de Armazenamento**

**Justificativa para Parquet como formato preferencial:**[39][40][41]
- **Armazenamento colunar:** Otimizado para consultas anal√≠ticas e agrega√ß√µes[40][39]
- **Compress√£o eficiente:** Reduz drasticamente o tamanho dos arquivos (at√© 80% em rela√ß√£o a CSV)[39][40]
- **Performance:** Leitura at√© 100x mais r√°pida que CSV para an√°lises[40]
- **Compatibilidade:** Padr√£o da ind√∫stria, suportado por todos os frameworks (Spark, Hadoop)[41][39]

**Outros formatos complementares:**[42][39]
- **CSV:** Para dados brutos iniciais e integra√ß√£o com ferramentas simples[39][40]
- **Avro:** Para dados em streaming com esquema evolutivo[42][39]
- **JSON:** Para dados semi-estruturados preservando esquema[39]

### Alinhamento com Requisitos do Trabalho

Sua arquitetura atende completamente aos requisitos especificados:[1]

‚úÖ **Camadas de Ingest√£o:** Batch e streaming implementadas[3][1]
‚úÖ **Camada de Armazenamento:** Arquitetura Medalh√£o com formatos apropriados[1][2]
‚úÖ **Camada de Processamento:** Motor distribu√≠do (Spark/Hadoop) para transforma√ß√µes[17][1]
‚úÖ **Camada de Consumo:** BI, ML, APIs e consultas ad-hoc[29][1][5]
‚úÖ **Governan√ßa:** Metadados, linhagem, qualidade e seguran√ßa[21][12][14]
‚úÖ **Suporte a ML:** Infraestrutura robusta com acesso direto √† Silver para Data Science[8][1][5]
‚úÖ **Tipos de dados:** Estruturados, semi-estruturados e n√£o estruturados[4][1]
‚úÖ **Flexibilidade de acesso:** M√∫ltiplos caminhos de consumo (Gold, Silver, APIs)[4][5][2]

### Fluxos de Dados Principais

#### **Fluxo 1: An√°lise de Neg√≥cio (Executivos/Analistas)**
SOURCES ‚Üí BATCH/STREAMING ‚Üí BRONZE ‚Üí PROCESSING ‚Üí SILVER ‚Üí GOLD ‚Üí **C1 (BI e Dashboards)**

- Dados pr√©-agregados e otimizados para performance m√°xima[29][2]

#### **Fluxo 2: An√°lise Explorat√≥ria (Data Scientists)**
SOURCES ‚Üí BATCH/STREAMING ‚Üí BRONZE ‚Üí PROCESSING ‚Üí **SILVER -.-> C2 (ML/Data Science)**

- Dados refinados mantendo granularidade para modelagem[11][5]

#### **Fluxo 3: Consultas Ad-hoc (Analistas)**
SOURCES ‚Üí BATCH/STREAMING ‚Üí BRONZE ‚Üí PROCESSING ‚Üí **SILVER -.-> C5 (Consultas SQL)**

- Acesso r√°pido a dados limpos para explora√ß√£o[4][5]

#### **Fluxo 4: Integra√ß√£o Externa**
SOURCES ‚Üí BATCH/STREAMING ‚Üí BRONZE ‚Üí PROCESSING ‚Üí GOLD ‚Üí **C3 (APIs de Dados)**

- Exposi√ß√£o controlada de dados via APIs REST[33][34]

#### **Fluxo 5: Recomenda√ß√£o de Produtos (Caso de Uso Principal)**
SOURCES (Navega√ß√£o + Compras) ‚Üí STREAMING ‚Üí BRONZE ‚Üí PROCESSING ‚Üí SILVER -.-> **C2 (ML/Recomenda√ß√£o)**

- Dados frescos em tempo real alimentam modelo de recomenda√ß√£o[8][1][5]

### Vantagens Competitivas da Arquitetura

Esta arquitetura oferece √† E-Shop:[8][1][5]

**Escalabilidade:** Cresce conforme o volume de dados aumenta, suportando crescimento de 10x ou mais[18][4]

**Flexibilidade:** Suporta novos tipos de dados sem reestrutura√ß√£o completa[4][5]

**Governan√ßa robusta:** Atende LGPD, garante qualidade dos dados e rastreabilidade completa[24][12][14]

**Insights em tempo real:** Combina√ß√£o de batch (hist√≥rico profundo) e streaming (eventos imediatos)[3][7]

**Personaliza√ß√£o:** Base para recomenda√ß√µes e marketing direcionado, essencial para reten√ß√£o de clientes[32][8]

**Custo-efetivo:** Armazenamento em data lake √© mais econ√¥mico que data warehouse, com flexibilidade aumentada[18][23]

**Democratiza√ß√£o:** Acesso controlado mas amplo aos dados em m√∫ltiplos n√≠veis (Gold, Silver, APIs)[4][5]

**Inova√ß√£o acelerada:** Data Scientists t√™m acesso r√°pido a dados granulares para experimenta√ß√£o r√°pida[11][5]

### Resumo das Mudan√ßas Implementadas

A adi√ß√£o da conex√£o `SILVER -.-> C5 & C2` (tracejada) reflete uma pr√°tica recomendada moderna onde:[11][2]

1. **C2 (Data Science):** Acesso direto √† Silver permite trabalhar com dados granulares, ideal para treinamento de modelos e experimenta√ß√£o[5][11]
2. **C5 (Consultas Ad-hoc):** Acesso direto √† Silver oferece ponto √≥timo entre performance e granularidade para an√°lises explorat√≥rias[4][5]

Esta flexibilidade n√£o compromete a seguran√ßa (GOV3 ainda controla acesso) nem a qualidade (GOV5 valida Silver), apenas permite que dados refinados sejam consumidos diretamente sem necessidade de agrega√ß√£o pr√©via na Gold.[11][2]

Esta arquitetura representa uma solu√ß√£o moderna, escal√°vel, flex√≠vel e aderente √†s melhores pr√°ticas da ind√∫stria para implementa√ß√£o de data lakes em ambientes de e-commerce.[9][5][2][11]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/134068334/a029afc8-9e1c-4980-b379-8cfe9a6bba04/Trabalho.pdf)
[2](https://www.robertodiasduarte.com.br/entenda-a-medallion-architecture-em-data-lakehouse/)
[3](https://blog.grancursosonline.com.br/ingestao-de-dados-conceitos/)
[4](https://wevy.cloud/blog-data-lake/)
[5](https://www.databricks.com/discover/data-lakes)
[6](https://kondado.com.br/blog/blog/2022/11/11/o-que-e-ingestao-de-dados/)
[7](https://www.programmers.com.br/blog/stream-data-lake-talvez-a-resposta-seja-arquitetura-lambda/)
[8](https://www.salesforce.com/br/blog/data-lake/)
[9](https://www.databricks.com/br/glossary/medallion-architecture)
[10](https://www.robertodiasduarte.com.br/guia-da-metodologia-medallion-architecture-para-data-lakehouse/)
[11](https://blog.dsacademy.com.br/arquitetura-medalhao-o-guia-definitivo-para-organizar-o-data-lakehouse-fundamentos/)
[12](https://www.astera.com/pt/type/blog/metadata-management/)
[13](https://www.cienciaedados.com/data-lake-a-evolucao-do-armazenamento-e-processamento-de-dados/)
[14](https://www.alura.com.br/artigos/governanca-de-dados-data-lake)
[15](https://www.reddit.com/r/dataengineering/comments/1ddkse6/data_modeling_in_medallion_architecture/)
[16](https://blog.dsacademy.com.br/como-controlar-verificacoes-de-qualidade-de-dados-no-data_lake/)
[17](https://hadoop.com.br/tecnologias/processamento/apache-spark)
[18](https://aws.amazon.com/pt/compare/the-difference-between-hadoop-vs-spark/)
[19](https://aws.amazon.com/pt/what-is/apache-spark/)
[20](https://sol.sbc.org.br/index.php/sbbd/article/download/37270/37053/)
[21](https://www.alteryx.com/pt-br/glossary/data-lineage)
[22](https://blog.dsacademy.com.br/linhagem-de-dados-tecnicas-e_exemplos/)
[23](https://www.objective.com.br/insights/data-lake/)
[24](https://repositorio.ufpe.br/handle/123456789/49411)
[25](https://blog.tripla.com.br/criptografia-de-dados-na-lgpd/)
[26](https://repositorio.ufsc.br/bitstream/handle/123456789/247351/PGCC1233-D.pdf?sequence=1)
[27](https://lexcompliance.com.br/lgpd/)
[28](https://www.programaria.org/qualidade-de-dados-o-que-e-como-medir-e-garantir/)
[29](https://ncs.net.br/insights/quais-sao-as-ferramentas-de-bi-mais-conhecidas-e-como-escolher)
[30](https://translate.google.com/translate?u=https%3A%2F%2Fwww.integrate.io%2Fblog%2Ftop-bi-visualization-tools%2F&hl=pt&sl=en&tl=pt&client=srp)
[31](https://www.redhat.com/en/topics/data-storage/what-is-a-data-lake)
[32](https://www.totvs.com/blog/inteligencia-dados/data-lake/)
[33](https://learn.microsoft.com/pt-br/rest/api/datalakeanalytics/)
[34](https://docs.aws.amazon.com/pt_br/lake-formation/latest/dg/aws-lake-formation-api-aws-lake-formation-api-settings.html)
[35](https://learn.microsoft.com/pt-br/rest/api/storageservices/data-lake-storage-gen2)
[36](https://docs.oracle.com/pt-br/solutions/data-platform-lakehouse/index.html)
[37](https://site.sauter.digital/?p=431)
[38](https://encord.com/blog/data-lake-guide/)
[39](https://www.reddit.com/r/dataengineering/comments/1cbx8bb/preferred_file_format_and_why_csv_json_parquet/)
[40](https://www.datacamp.com/pt/tutorial/apache-parquet)
[41](https://www.ibm.com/docs/pt-br/db2/12.1.x?topic=warehouse-supported-file-formats)
[42](https://translate.google.com/translate?u=https%3A%2F%2Fsqream.com%2Fblog%2Favro-vs-parquet-which-file-format-is-right-for-your-data%2F&hl=pt&sl=en&tl=pt&client=srp)
